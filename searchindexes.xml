<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>postgresql学习（一）：安装、权限体系</title><url>/posts/postgresql-learn-install/</url><categories><category>postgresql</category></categories><tags><tag>数据库</tag><tag>postgresql</tag></tags><content type="html"><![CDATA[postgresql学习（一）：安装、权限体系
安装 可以通过不同Linux发行版的包管理器进行安装，以Ubuntu为例： 点击进入 postgresql下载网页 ，选择相应的平台和Liunx发行版，按照提示执行：
# Create the file repository configuration: sudo sh -c &#39;echo &#34;deb https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main&#34; &gt; /etc/apt/sources.list.d/pgdg.list&#39; # Import the repository signing key: wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - # Update the package lists: sudo apt-get update # Install the latest version of PostgreSQL. # If you want a specific version, use &#39;postgresql-12&#39; or similar instead of &#39;postgresql&#39;: sudo apt-get -y install postgresql 也可以根据源代码构建。
启动、停止、重启命令：
sudo /etc/init.d/postgresql start # 开启 sudo /etc/init.d/postgresql stop # 关闭 sudo /etc/init.d/postgresql restart # 重启 安装后默认启动，默认监听为127.0.0.1:5432，只能本地访问。 修改为任意地址访问：
#修改后使PostgreSQL可以接受来自任意IP的连接请求： sudo vi /etc/postgresql/16/main/postgresql.conf listen_addresses = &#39;*&#39; #默认pg只允许本机通过密码认证登录，修改后即可以对任意IP访问进行密码验证 sudo vi /etc/postgresql/16/main/pg_hba.conf # TYPE DATABASE USER CIDR-ADDRESS METHOD host all all 0.0.0.0/0 scram-sha-256 之后重启postgresql。
命令行使用：
sudo -i -u postgres psql 用户权限 引用： 浅谈PostgreSQL用户权限 赋予权限： 首先你把数据库connect的权限赋予用户 再则你需要把table1所在的schema的使用权限赋予用户 最后你需要把table的权限赋予用户
#创建用户、密码 CREATE USER test WITH PASSWORD &#39;1111&#39;; #创建数据库 create database db1 owner test; #查看现有用户及权限 \du #查看所有数据库 \l #使用用户test登录db1 \c db1 test #赋予创建数据库权限 alter user test createdb; #赋予创建schema权限 GRANT CREATE ON DATABASE db1 TO test; ]]></content></entry><entry><title>Getting Friendly With Cpu Caches</title><url>/posts/getting-friendly-with-cpu-caches/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[文章翻译，原文链接：https://www.ardanlabs.com/blog/2023/07/getting-friendly-with-cpu-caches.html
理解 CPU 缓存的重要性，以及利用CPU缓存提升程序的性能和质量。文中基准测试的结果替换为我本地执行的结果。
介绍 当 CPU 需要访问一段数据时，数据需要从主存储器进入处理器。
这种架构看起来是这样的：
图一：
图1显示了一段数据必须经过的不同内存层才能被处理器访问。 每个CPU都有自己的L1和L2缓存，L3缓存在所有CPU之间共享。 当数据最终进入L1或L2高速缓存时，处理器可以出于执行目的访问它。 在英特尔体系结构上，三级缓存维护L1和L2中的内容的副本。
性能最终取决于数据流入处理器的效率。 从图中可以看出，由于数据需要移动和复制，内存访问速度比访问一级缓存慢大约80倍。
一个例子 这可能很有趣，但作为开发人员，这对您有什么影响？
一起来看看。
假设您有以下 User 结构体：
Listing 1:
type Image [128 * 128]byte type User struct { Login string Active bool Icon Image Country string } Listing 1展示了一个名为 User 的结构体，在第 1 行，该结构体有一个Image字段，定义为 128×128 的字节数组。 这是一个 16k 字节（16,384）的连续内存块。
你可能想知道为什么图标字段是用户结构的一部分？ 其中一个原因可能是为了在客户端从系统中检索用户时节省 API 调用。 这样，客户端就不需要进行第二次调用来获取图标图像了。
现在假设您需要添加一个 API，用于按国家/地区统计系统中的活跃用户数量。
Listing 2
// CountryCount returns a map of countries to the number of active users. func CountryCount(users []User) map[string]int { counts := make(map[string]int) // country -&gt; count for _, u := range users { if !u.Active { continue } counts[u.Country]++ } return counts } 基准测试 这个 API 工作得很好，但随后您决定对该函数进行基准测试。
Listing 3
var users []User func init() { const size = 10_000 countries := []string{ &#34;AD&#34;, &#34;BB&#34;, &#34;CA&#34;, &#34;DK&#34;, } users = make([]User, size) for i := 0; i &lt; size; i++ { users[i].Active = i%5 &gt; 0 // 20% non active users[i].Country = countries[i%len(countries)] } } func BenchmarkCountryCount(b *testing.B) { for i := 0; i &lt; b.N; i++ { m := CountryCount(users) if m == nil { b.Fatal(m) } } } Listing 3 展示了基准测试代码。 在第03-18行，声明了一个init函数来初始化基准测试的数据。 在第13行，构造了一个切片来容纳10000个用户，其中20%被设置为非活动用户。 在第20-27行，声明并编写基准函数以调用基准循环中的CountryCount函数。
Listing 4
我本地运行的结果：
$ go test -bench . -benchtime 10s -count 5 goos: linux goarch: amd64 pkg: test cpu: Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz BenchmarkCountryCount-4 1966 5883585 ns/op BenchmarkCountryCount-4 2044 5880595 ns/op BenchmarkCountryCount-4 2034 5877615 ns/op BenchmarkCountryCount-4 2008 5891777 ns/op BenchmarkCountryCount-4 2062 5859283 ns/op PASS ok test 62.566s Listing 4 显示了如何运行基准测试并提供结果。 第一行使用 Go test 命令运行基准函数 5 次，每次至少 10 秒。 基准测试结果平均为每次操作 5,883,585 纳秒，即每次操作 ~5.88ms。
注意：运行基准测试时应注意单位。 go 工具通常以纳秒为单位进行报告，但您可能需要转换为其他单位。 常用的单位有纳秒 (ns)、微秒 (μs) 和毫秒 (ms)。 如果您看到以下以纳秒为单位的数字 123,456,789，则 789 为 ns，456 为 μs，123 为 ms。逗号是你的朋友。
你应该为你的代码设定性能目标，如果~5.88ms达到了这些目标，那么就不要为了让代码运行得更快而修改代码！
假设您需要更好的性能。如何开始对性能进行剖析？你应该寻找什么？
让我们从检查缓存未命中情况开始。
缓存未命中 让我们来看看我用来运行此代码的CPU缓存的大小：
Listing 5
$ lscpu --caches NAME ONE-SIZE ALL-SIZE WAYS TYPE LEVEL SETS PHY-LINE COHERENCY-SIZE L1d 32K 128K 8 Data 1 64 1 64 L1i 32K 128K 8 Instruction 1 64 1 64 L2 256K 1M 4 Unified 2 1024 1 64 L3 6M 6M 12 Unified 3 8192 1 64 Listing 5 显示了如何获取 CPU 缓存信息。您可以看到每个缓存的大小：L1 为 32K，L2 为 256M，L3 为 6M。
请记住，User 结构体中的 Icon 字段需要约 16k 字节的连续内存。 当您将其与我们为基准测试创建的 10k 用户相乘时，该切片需要约 163 MiB 的连续内存。 这意味着该切片一旦构建就无法完全放入任何缓存中。
这将导致硬件对内存造成冲击，因为它不断需要将读取的切片中的每个元素的数据从主内存移动到缓存。 即使内存是连续布局的，系统也会表现得好像存在随机存取内存一样。
要验证缓存未命中是否不会让程序运行得尽可能快，您可以使用 Linux [perf][https://perf.wiki.kernel.org/index.php/Main_Page] 程序。 perf 命令适用于可执行文件，因此您需要直接运行测试可执行文件，而不是通过 go test 运行。
默认情况下，将在运行测试结束时删除测试可执行文件， 因此请使用 go test -c 标志保留执行文件。
Listing 6
$ go test -c $ ls *.test users.test Listing 6 显示了如何构建并保持测试可执行文件。获得测试可执行文件后，您可以在 perf 下运行它。
Listing 7
$ perf stat -e cache-misses ./users.test -test.bench . -test.benchtime=10s -test.count=5 goos: linux goarch: amd64 pkg: test cpu: Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz BenchmarkCountryCount-4 1958 5927578 ns/op BenchmarkCountryCount-4 2007 5966882 ns/op BenchmarkCountryCount-4 2005 6337220 ns/op BenchmarkCountryCount-4 1824 6805542 ns/op BenchmarkCountryCount-4 1987 6004175 ns/op PASS Performance counter stats for &#39;./test.test -test.bench . -test.benchtime=10s -test.count=5&#39;: 7855698103 cache-misses:u 63.845414182 seconds time elapsed 63.361868000 seconds user 0.849890000 seconds sys Listing 7 展示了如何使用 perf 命令运行测试可执行文件。 您可以看到核心 CPU 和原子 CPU 上发生的缓存未命中次数。 在CPU上执行基准测试期间，缓存未命中次数约为 78 亿次。
使用Slice 如何减少缓存未命中次数？如果我们缩小 User 结构体的大小，使缓存中同时容纳更多的用户值， 就可以减少缓存未命中的次数。 现在，L1 缓存中一次只能容纳几个用户值。使用切片可以大大减小 User 值的大小。
但这为什么会有帮助呢？让我们看一下语言中切片值的声明。
https://github.com/golang/go/blob/master/src/runtime/slice.go#L15 Listing 8
type slice struct { array unsafe.Pointer len int cap int } Listing 8显示了 Go 中切片的声明。在 64 位操作系统上，整数为 64 位或 8 个字节。 这意味着切片值总共有 24 个字节。 通过使用切片，我们可以将用户值的大小从约 16k+ 字节减少到 24 字节。一个重大的变化。
Listing 9
type Image []byte type User struct { Login string Active bool Icon Image Country string } func CountryCount(users []User) map[string]int { counts := make(map[string]int) // country -&gt; count for _, u := range users { if !u.Active { continue } counts[u.Country]++ } return counts } Listing 9显示了 Image 和 User 类型的新实现。唯一的变化是第 03 行，它使用了切片和底层类型。
为了公平起见，让我们更改基准代码以在用户初始化时为icons分配内存。该内存不再随着users的构造而分配。
Listing 10
var users []User func init() { const size = 10_000 countries := []string{ &#34;AD&#34;, &#34;BB&#34;, &#34;CA&#34;, &#34;DK&#34;, } users = make([]User, size) for i := 0; i &lt; size; i++ { users[i].Active = i%5 &gt; 0 // 20% non active	users[i].Country = countries[i%len(countries)] users[i].Icon = make([]byte, 128*128) } } 新的基准代码唯一的变化是增加了1行，为 Icon 字段分配内存。
现在让我们再次运行基准测试。
Listing 11
$ go test -bench . -benchtime=10s -count=5	goos: linux goarch: amd64 pkg: test cpu: Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz BenchmarkCountryCount-4 99472 119575 ns/op BenchmarkCountryCount-4 100154 119601 ns/op BenchmarkCountryCount-4 101049 119761 ns/op BenchmarkCountryCount-4 100350 119680 ns/op BenchmarkCountryCount-4 100460 119528 ns/op PASS ok test 66.171s Listing 11显示了基准测试的第二次运行。 您可以看到现在每个操作的平均值为 119,601ns 或 ~119 微秒。比以前的版本快大约~49.4倍。
为了确保缓存未命中次数更少，让我们再次在 perf 下运行代码。
Listing 12
$ perf stat -e cache-misses ./users.test -test.bench . -test.benchtime=10s -test.count=5 goos: linux goarch: amd64 pkg: test cpu: Intel(R) Core(TM) i5-6500 CPU @ 3.20GHz BenchmarkCountryCount-4 95760 143196 ns/op BenchmarkCountryCount-4 97128 129585 ns/op BenchmarkCountryCount-4 89460 129624 ns/op BenchmarkCountryCount-4 95626 121016 ns/op BenchmarkCountryCount-4 95607 126021 ns/op PASS Performance counter stats for &#39;./users.test -test.bench . -test.benchtime=10s -test.count=5&#39;: 212259011 cache-misses:u 68.057638064 seconds time elapsed 67.290619000 seconds user 1.162602000 seconds sys Listing 12显示了 的 perf 第二次运行。 您可以看到现在CPU上有2亿次缓存未命中。回到Listing 6，您将看到原始值以十亿为单位。
现在，缓存中容纳了更多的User，我们看到缓存未命中次数减少了，性能也提高了。
总结 我喜欢为客户优化代码的原因之一是我需要学习的知识范围。不仅包括数据结构和算法，还包括计算机体系结构、Go 运行时如何工作、网络等等。我还可以使用很酷的新工具（例如 perf）
您从一个小的代码更改中获得了显着的性能提升，但并非没有免费的午餐。
代码风险更大，因为现在 Icon 可能是 nil .
您还需要在每个结构的 User 堆上分配内存，堆分配需要更多时间。 最后，垃圾收集器需要更加努力地工作，因为我们在堆上有更多的数据。
]]></content></entry><entry><title>bytebufferpool 源码阅读</title><url>/posts/bytebufferpool/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>byte buffer pool</tag></tags><content type="html"><![CDATA[高性能字节池 bytebufferpool 源码阅读
仓库地址： https://github.com/valyala/bytebufferpool 使用 package main import ( &#34;fmt&#34; &#34;github.com/valyala/bytebufferpool&#34; ) func main() { // 从池中取出一个对象 b := bytebufferpool.Get() b.WriteString(&#34;hello&#34;) b.WriteByte(&#39;,&#39;) b.WriteString(&#34; world!&#34;) fmt.Println(b.String()) // 用完后放回去 bytebufferpool.Put(b) } 源码阅读 源码主要包含两个文件，bytebuffer.go 和 pool.go, bytebuffer.go主要定义了一个ByteBuffer结构体以及一些读取、写入的方法， 池的实现主要是在pool.go。
pool的结构体定义如下：
type Pool struct { calls [steps]uint64 //记录不同长度的索引的使用次数 calibrating uint64 //防止校准并发的标志位 defaultSize uint64 //初始化[]byte的默认值 maxSize uint64 //可放回pool中的最大[]byte长度 pool sync.Pool } 首先看Get方法，从sync.Pool中取出一个对象，如果没有就初始化一个ByteBuffer，然后返回。
func (p *Pool) Get() *ByteBuffer { v := p.pool.Get() if v != nil { return v.(*ByteBuffer) } return &amp;ByteBuffer{ B: make([]byte, 0, atomic.LoadUint64(&amp;p.defaultSize)), } } 当对象使用完，放回池中时，使用index方法根据[]byte的长度计算出索引。
// minBitSize=6 steps=20 // 将[]byte的长度映射为0-19的索引 func index(n int) int { n-- n &gt;&gt;= minBitSize idx := 0 for n &gt; 0 { n &gt;&gt;= 1 idx++ } if idx &gt;= steps { idx = steps - 1 } return idx } 然后给相应位置的索引+1，如果大于42000这个阈值，就触发校准
if atomic.AddUint64(&amp;p.calls[idx], 1) &gt; calibrateCallsThreshold { p.calibrate() } 如果要回收的对象的容量小于maxSize 或者 maxSize为0(默认值),就执行reset后放回池中，容量超过maxSize就丢弃。
maxSize := int(atomic.LoadUint64(&amp;p.maxSize)) if maxSize == 0 || cap(b.B) &lt;= maxSize { b.Reset() p.pool.Put(b) } 关键在于calibrate方法，在区间的使用次数超过阈值之后，就会触发校准，调整defaultSize和maxSize的值。
首先使用原子操作修改calibrating，防止并发。
if !atomic.CompareAndSwapUint64(&amp;p.calibrating, 0, 1) { return } 然后遍历calls数组，得出所有区间调用次数和容量，再进行排序。然后defaultSize设置为第一个的容量，即使用次数最多的。
a := make(callSizes, 0, steps) var callsSum uint64 for i := uint64(0); i &lt; steps; i++ { calls := atomic.SwapUint64(&amp;p.calls[i], 0) callsSum += calls a = append(a, callSize{ calls: calls, size: minSize &lt;&lt; i, }) } sort.Sort(a) defaultSize := a[0].size 然后遍历计算maxSize，取调用次数为总次数前95%的buffer的最大容量。 比如：callsSum=1000，即调用了1000次，那么maxSum=950，然后遍历加上调用次数，如果总数小于950， 且size &gt; maxSize, 就把当前size的值赋值给maxSize，最后得出最大的maxSize。
maxSize := defaultSize //maxPercentile=0.95 maxSum := uint64(float64(callsSum) * maxPercentile) callsSum = 0 for i := 0; i &lt; steps; i++ { if callsSum &gt; maxSum { break } callsSum += a[i].calls size := a[i].size if size &gt; maxSize { maxSize = size } } 最后使用原子操作修改defaultSize和maxSize
atomic.StoreUint64(&amp;p.defaultSize, defaultSize) atomic.StoreUint64(&amp;p.maxSize, maxSize) 总结 相比sync.Pool, 这个库可用根据实际使用的数据的大小，实时调整[]byte对象的大小， 抛弃调用次数比较少的对象，防止将使用较少的大容量对象放回对象池 ，从而占用太多内存。
]]></content></entry><entry><title>在Go中初始化大型static Maps</title><url>/posts/static-map-initialization-in-go/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[文章翻译，原文链接：https://www.dolthub.com/blog/2023-06-16-static-map-initialization-in-go/
这篇文章讨论了Go二进制文件中map数据的静态初始化的技术细节，以及处理性能影响的一些替代策略。这是我们技术博客系列中的一部分。我们每三周发布一篇新的系列文章。
在Dolt中，我们正在构建一个带有类似Git版本控制功能的SQL数据库。 它支持克隆、推送、拉取、分支、合并和差异等所有核心Git习语。 它使用Go语言实现，其协议和SQL方言与MySQL兼容。
在过去的几个月中，我们一直在改进我们的SQL引擎中的排序规则和Unicode支持。 我们所做的一个改变是向Dolt中添加了一些数据表，以更好地支持不同Unicode区域设置下字符串的本地化排序。 这涉及向Dolt二进制文件中添加了许多静态数据表。 我们最初的实现是使用static Maps，将这些maps编译到Dolt二进制文件中。 不久之后，一位同事在一个Pull Request中添加了许多大型static Maps到Dolt后，我们发现端到端测试变得非常缓慢。 这促使我们深入研究Go中static Map初始化的工作原理，并在后续版本中解决这个回归问题：
这篇博客是对Go工具链中static Maps初始化的实现方式进行简要探索，以及它在运行时的开销成本以及一些备选方法，用于在需要时处理相关问题。
背景 Dolt与MySQL一样，并且作为其MySQL兼容性的一部分，支持字符串的语言相关排序。 语言相关排序涉及将字符串相互比较，并得出语言用户所期望的相对顺序。 对于大多数字符编码和区域设置而言，这比简单比较字符串中字符或代码点的二进制表示更为复杂。原因包括：
相同字符串的不同表示在给定字符编码中可以有不同的二进制表示形式，根据用户在屏幕上的显示方式。例如，在UTF-32中，法语单词&quot;où&quot;可以用两个代码单元表示为：[U+006F, U+00F9]，或者用三个代码单元表示，带有表示重音的组合附加符号：[U+006F, U+0300, U+0075]。 不同语言对于相同字符的相对顺序有不同的规则。例如，在德语区域设置下，字符串列表[&ldquo;Aa&rdquo;, &ldquo;Od&rdquo;, &ldquo;Öd&rdquo;, &ldquo;Zz&rdquo;]应按相同顺序排序，但在瑞典语区域设置下应排序为[&ldquo;Aa&rdquo;, &ldquo;Od&rdquo;, &ldquo;Zz&rdquo;, &ldquo;Öd&rdquo;]。 你可以在Dolt中看到这一点的实际应用：
collations&gt; create table german (word varchar(32) primary key) collate utf8mb4_de_pb_0900_as_cs; collations&gt; create table swedish (word varchar(32) primary key) collate utf8mb4_sv_0900_as_cs; collations&gt; insert into german values (&#34;Aa&#34;),(&#34;Od&#34;),(&#34;Öd&#34;),(&#34;Zz&#34;); Query OK, 4 rows affected (0.02 sec) collations&gt; insert into swedish values (&#34;Aa&#34;),(&#34;Od&#34;),(&#34;Öd&#34;),(&#34;Zz&#34;); Query OK, 4 rows affected (0.01 sec) collations&gt; select * from german order by word asc; +------+ | word | +------+ | Aa | | Od | | Öd | | Zz | +------+ 4 rows in set (0.01 sec) collations&gt; select * from swedish order by word asc; +------+ | word | +------+ | Aa | | Od | | Zz | | Öd | +------+ 4 rows in set (0.00 sec) 由于存在这样的复杂性，实现与地区相关的排序通常涉及到调用排序算法相关的数据表，以获得字符串的适当顺序。
Dolt本身作为静态链接的二进制文件分发。我们非常喜欢它的分发模型的可接近性和易用性。 您只需下载Dolt的操作系统适当版本并运行即可。 因此，我们始终在二进制文件中提供这些表，以支持Dolt的排序。
Dolt的用户体验和典型交互方式与典型的SQL服务器也可能非常不同。 具体而言，Dolt用户通常以两种不同的方式与Dolt交互：
作为SQL服务器，长时间运行的Dolt进程通过TCP 和/或 Unix套接字接受SQL连接。 作为独立的二进制文件，在类似Git的工作流中频繁调用Dolt CLI来执行诸如创建分支、运行临时SQL查询、查看提交日志和执行合并等操作。 后一种情况与传统RDBMS实现的典型交互方式非常不同，这意味着使用Dolt的用户体验可能在很大程度上受到Dolt二进制启动延迟的影响。
我的同事最近向Dolt二进制文件添加了32MB以上的排序数据表，以更好地支持MySQL支持的许多Unicode排序。 这些最初是以与现有排序实现完全相同的方式完成的。 数据负载的大部分是作为静态初始化的Go map实现的，类似于：
var utf16_spanish_ci_Weights = map[rune]int32{ 9: 0, 10: 1, 11: 2, 12: 3, 13: 4, 133: 5, 8232: 6, // ... // ... // ... 24000+ lines later ... 65534: 59403, 65535: 59404, } PR合并后不久，我们注意到我们的端到端测试变得非常慢。 当我们进行基准测试时，发现由于static Maps，dolt &ndash;help的速度变慢了300%以上。 在意识到static Maps的运行时初始化成本后，我们将它们移动到embed数据文件中，在需要时再加载，修复了整个回归。
让我们来看看Go static Maps初始化的工作原理以及我们对其运行时开销的预期。
Static Map 初始化 static Maps的初始化发生在创建一个具有初始内容的Map时，该Map位于Go包的顶层。 与某些其他静态数据类型（包括原始类型、字符串、切片和所有这些类型的结构体）不同， 在Go中，static Maps是在程序初始化时动态分配和赋值的，而不是将其内容放到内存中并写入编译二进制文件的数据段中。例如：
package main var mymap = map[int]int{ 1: 1, 2: 2, 3: 3, } Go编译器将调用一个init函数，其中包括分配map并将元素插入其中。 代码看起来几乎与以下Go代码序列完全相同：
mymap = make(map[int]int, 3) mymap[1] = 1 mymap[2] = 2 mymap[3] = 3 调用了runtime.makemap_small和三次调用runtime.mapassign_fast64。
在当前版本的golang编译器中，随着map的大小变化，这种方法会略微改变。 受到代码大小的限制，如果map中有超过25个条目，编译器将移动键和值数据到静态数组中。 在这种情况下，init代码会循环遍历静态数组数据并将其插入动态分配的map中。
总体效果是，static Maps初始化的成本随着Go二进制文件中static Maps大小的增加大约呈线性增长。 在一些本地运行的实验中，我看到以下的缩放行为： 我们可以看到，一旦map初始化的成本高到足以开始产生影响，其成本就会近似于线性增长。
对开发工作流程的影响 除了生成的二进制文件的启动成本外，以static Maps初始化的形式存在的巨大代码也对编译时间和诸如go vet之类的操作的内存开销产生了负面影响。 这一点并不令人惊讶，因为需要编译的代码量要大得多。 在一个测试程序中，该程序包含一个具有2^20个整数条目的map，总共占据17MB的磁盘空间， go vet的最大常驻堆利用率超过了1.5GB，go build的常驻堆利用率超过了1.2GB， 构建该软件包需要超过12秒的时间。
一些解决方法 考虑到相关成本，我们可以采取许多不同的方法，以在启动开销、代码易用性和可访问性以及生成的初始化数据结构中可用的各种功能方面进行不同的权衡。 在这里，我们将讨论三个令人信服的替代方案，这些方案在转换后的复杂性和可用功能方面有所不同。根据您的用例，这些替代方案中的任何一个或所有方案都可能是合适的。
排序的静态数组 如果你能负担得起在二进制文件中嵌入的任何表的查找路径上的O(lg n)比较， 而且你主要关心的是启动开销，而不一定是与大的代码有效载荷相关的资源开销， 那么把maps转换成一个排序的静态数组可能是一个选择。使用这种方法，你会失去：
数据结构在运行时易于更改。 O(1) 时间复杂度 采用这种方法，您可能会牺牲嵌入式数组文字的易于手动编辑性。 如果采用这种方法，文字实际上需要进行排序，因此您应编写单元测试来进行断言。 作为额外的好处，这些同样的单元测试还可以在失败时生成嵌入排序结果的代码，以便开发人员可以轻松地将正确结果复制到代码中。
采用这种方法，上面的示例map可能如下所示：
type RuneCollationWeight struct { R rune W int } type RuneCollationWeights []RuneCollationWeight func (w RuneCollationWeights) Len() int { return len(w) } func (w RuneCollationWeights) Less(i, j int) bool { return w[i].R &lt; w[j].R } func (w RuneCollationWeights) Swap(i, j int) { w[i], w[j] = w[j], w[i] } func (w RuneCollationWeights) Get(r rune) (int, bool) { n := sort.Search(w.Len(), func(i int) bool { return w[i].R &gt;= r }) entry := w[n] if entry.R == r { return entry.W, true } else { return 0, false } } var utf16_spanish_ci_Weights = RuneCollationWeights{ {9, 0}, {10, 1}, {11, 2}, {12, 3}, {13, 4}, {133, 5}, {8232, 6}, // ... // ... // ... 24000+ lines later ... {65534, 59403}, {65535, 59404}, } 这里的代码实现了sort.Interface，因此可以进行一些健全性测试，例如sort.IsSorted(utf16_spanish_ci_Weights)。
使用embed减少代码量 根据实际情况，在 Go 代码中保留数组可能会对开发人员的工作效率产生不良影响， 例如编译和 go vet 时间的开销。 Go 通过其 embed 包提供了一种非常简单的方法，可以将二进制有效负载嵌入为 []bytes，甚至可以将整个目录树作为 fs.FS 实现嵌入。
使用这种方法，可以将大型静态数组从 Go 代码本身移出，并放入外部文件中。 在这样做时，需要考虑将数据本身序列化到外部文件中。该序列化需要以跨平台的方式进行处理。 还需要添加能够在更改文件时生成这些文件的程序或构建过程。 对于上面的示例，可以编写一个简单的程序，将数据序列化为大端 int32：
func SerializeWeights(w io.Writer, weights RuneCollationWeights) error { sort.Sort(weights) for _, weight := range weights { if weight.W &gt; math.MaxInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is larger than MaxInt32&#34;, weight.R, weight.W) } if weight.W &lt; math.MinInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is smaller than MinInt32&#34;, weight.R, weight.W) } err = binary.Write(w, binary.BigEndian, int32(weight.R)) if err != nil { return err } err = binary.Write(w, binary.BigEndian, int32(weight.W)) if err != nil { return err } } return nil } 正如您所看到的，我们可以选择将权重排序作为构建步骤的一部分，这可能会使与这些生成器程序源代码一起检入的数组的处理更加容易。 要将这些文件发布并在二进制文件中使用它们，我们可以采用上述方法，但这次利用使用 embed 包生成的文件：
import _ &#34;embed&#34; //go:embed utf16_spanish_ci_Weights.bin var utf16_spanish_ci_Weights_bin []byte type BinaryRuneCollationWeights []byte func (w BinaryRuneCollationWeights) Len() int { // There are two 32-bit integers per entry return len(w) / 8 } func (w BinaryRuneCollationWeights) Get(r rune) (int, bool) { n := sort.Search(w.Len(), func(i int) bool { entryR := binary.BigEndian.Uint32(w[i*8:]) return rune(entryR) &gt;= r }) entryR := binary.BigEndian.Uint32(w[n*8:]) if rune(entryR) == r { return int(int32(binary.BigEndian.Uint32(w[n*8+4:]))), true } else { return 0, false } } var utf16_spanish_ci_Weights = BinaryRuneCollationWeights(utf16_spanish_ci_Weights_bin) 懒加载Maps 如果您想要 O(1) 时间复杂度，并且特别是如果您希望在用初始内容填充map后保持map运行时的可变性， 则在首次访问时懒加载map可能是一个不错的选择。 如果您的程序不是所有运行都需要访问map（或在您有多个map的情况下不是所有map都需要访问），那么这尤其正确。 实现这个的最简单方法是将map访问移至函数调用后面，并在该函数内使用 sync.Once 调用来填充map内容。类似于这样的东西：
import &#34;sync&#34; var utf16_spanish_ci_Weights_ map[rune]int var utf16_spanish_ci_Weights_once sync.Once func utf16_spanish_ci_Weights() map[rune]int { utf16_spanish_ci_Weights_once.Do(func() { utf16_spanish_ci_Weights_ = map[rune]int{ 9: 0, 10: 1, 11: 2, 12: 3, 13: 4, 133: 5, 8232: 6, // ... // ... // ... 24000+ lines later ... 65534: 59403, 65535: 59404, } }) return utf16_spanish_ci_Weights_ } 每次访问您的map都应该通过 utf16_spanish_ci_Weights() 进行访问。 如果您只关心启动初始化开销，那么这种转换就足够了。 utf16_spanish_ci_Weights() 函数内部的代码几乎与 init 函数中编译的代码相同， 但所有这些工作都被延迟到实际访问权重map时才执行。
如果您想要将代码负载本身从常见的编译、测试或依赖代码路径中取出， 则可以像上面那样使用 embed，并从 sync.Once 回调中的序列化内容中构建map。类似于这样的东西：
func utf16_spanish_ci_Weights() map[rune]int { utf16_spanish_ci_Weights_once.Do(func() { bin := utf16_spanish_ci_Weights_bin utf16_spanish_ci_Weights_ = make(map[rune]int, len(bin) / 8) for len(bin) &gt; 0 { r := rune(binary.BigEndian.Uint32(bin[:])) w := int(int32(binary.BigEndian.Uint32(bin[4:]))) utf16_spanish_ci_Weights_[r] = w bin = bin[8:] } }) return utf16_spanish_ci_Weights_ } 这是我们在 dolt 中实现的解决方案，因为它很简单，并且对使用这些数据表内容的代码影响最小。
完美哈希 由于依赖于 embed 的解决方案需要外部程序处理数据表并将其放入程序可以使用的格式中（而不是仅仅依靠 Go 编译器的能力来布局程序的静态数据）， 因此我们可以进一步采用一种紧凑、哈希方式来布局数据，这仍然允许 O(1) 访问所有条目， 但不需要在运行时构建map。我们想要的结构是一个查找表，建立在我们原始map中的键的计算最小完美哈希函数上。在Golang中有许多高质量的最小完美哈希实现。
我们为map的keys构建和序列化完美哈希函数，作为与map内容本身分开的有效负载。 该有效负载通常比键和值本身的集合小得多。 我们将键和值嵌入为单独的二进制有效负载，通过完美哈希间接引用。以下是使用 bbhash 包的运行示例：
func SerializeWeights(wWr, hWr io.Writer, weights []RuneCollationWeight) error { keys := make([]uint64, len(weights)) for i, weight := range weights { keys[i] = uint64(weight.R) } hash, err := bbhash.New(bbhash.Gamma, keys) if err != nil { return err } err = hash.MarshalBinary(hWr) if err != nil { return err } ordered := make([]RuneCollationWeight, len(weights)) for _, weight := range weights { i := hash.Find(uint64(weight.R)) - 1 ordered[i] = weight } for _, weight := range ordered { if weight.W &gt; math.MaxInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is larger than MaxInt32&#34;, weight.R, weight.W) } if weight.W &lt; math.MinInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is smaller than MinInt32&#34;, weight.R, weight.W) } err = binary.Write(wWr, binary.BigEndian, int32(weight.R)) if err != nil { return err } err = binary.Write(wWr, binary.BigEndian, int32(weight.W)) if err != nil { return err } } return nil } import _ &#34;embed&#34; //go:embed utf16_spanish_ci_Weights.bin var utf16_spanish_ci_Weights_bin []byte //go:embed utf16_spanish_ci_Weights_hash.bin var utf16_spanish_ci_Weights_hash_bin []byte var utf16_spanish_ci_Weights_hash *bbhash.BBHash var utf16_spanish_ci_Weights HashedRuneCollationWeights func init() { var err error utf16_spanish_ci_Weights_hash, err = bbhash.UnmarshalBBHash(bytes.NewReader(utf16_spanish_ci_Weights_hash_bin)) if err != nil { panic(err) } utf16_spanish_ci_Weights = HashedRuneCollationWeights{ H: utf16_spanish_ci_Weights_hash, B: utf16_spanish_ci_Weights_bin, } } type HashedRuneCollationWeights struct { H *bbhash.BBHash B []byte } func (w HashedRuneCollationWeights) Get(r rune) (int, bool) { i := h.Find(uint64(r)) - 1 off := i * 8 if off &lt; len(w.B) { entryR := rune(binary.BigEndian.Uint32(w.B[off:])) entryW := int(int32(binary.BigEndian.Uint32(w.B[off+4:]))) if entryR == r { return entryW, true } } return 0, false } 如果您试图削减初始化开销，那么这可能是您想要采取的方法， 但实际上有很大一部分二进制调用实际上确实需要访问这些嵌入式数据表的至少一些部分。 在这种情况下，无法避免支付初始化开销，因此最好尽可能少。
这种方法的一些缺点可能包括：
重新生成序列化数据表需要更多时间，因为它需要在生成时计算键集的最小完美哈希。 如果数据表被检入源代码控制，它们将按哈希顺序存储，而不是按排序顺序存储。这通常会导致更少的二进制差异和更高的存储开销，因为版本之间的更改会更大，而SCM使用的增量编码也不太有效。 生成的二进制文件略大，因为它存储足够的数据来重构哈希表map以及数据表的实际内容。 值得注意的是，上面 init 函数中的 bbhash.UnmarshalBBHash 调用的静态初始化开销介于类似于 []byte 的纯静态数据和初始化map之间。 它需要解析一些位向量，这些位向量在聚合大小为 O(n)，通常每个键不到五个位，并且它通过并解释大多数加载的数据作为小端整数。 这可以非常快地完成，比构建哈希map快得多，但它不像根本不访问内存那样便宜——如果大型静态数组写入 Golang 二进制文件的数据段中，如果它们未被访问，则在启动时甚至不需要从磁盘中分页。
如果您通常喜欢完美哈希的某些属性，但不喜欢特定的初始化开销，将 UnmarshalBBHash 移动为延迟加载也可以正常工作。
总结 概括一下，我们研究了以下在Dolt二进制文件中嵌入大型静态查找表的方法：
Approach Startup Cost First Access Cost Code Cost Build Complexity Access Asymptotics Runtime Mutability Static Map ★☆☆☆☆ ★★★★★ ★☆☆☆☆ ★★★★★ O(1) ✔️ Lazy Map ★★★★★ ★☆☆☆☆ ★☆☆☆☆ ★★★★★ O(1) ✔️ Lazy Map, using embed ★★★★★ ★☆☆☆☆ ★★★★★ ★★☆☆☆ O(1) ✔️ Static Array ★★★★★ ★★★★★ ★☆☆☆☆ ★★★★★ O(lg n)	❌ Static Array, using embed ★★★★★ ★★★★★ ★★★★★ ★★☆☆☆ O(lg n) ❌ Perfect Hash ★★★★☆ ★★★★★ ★★★★★ ★☆☆☆☆ O(1) ❌ 在 Dolt 本身中，我们最终使用了延迟初始化的map，我们从 embed 数据表中在第一次访问时构建。 外部程序将序列化的数据表写出，然后我们将二进制有效负载检入源代码控制。 对于我们来说，这很有效，因为这些表缓慢地变化，每个表的中等大小有很多，对于我们大多数客户的大多数 Dolt 调用，只访问其中很少的几个。
正如您所看到的，Go 工具链和生态系统提供了许多近在手边的方法，希望能够满足您在二进制文件中发布大型查找表的分发和开发人员工程学需求。 如果您对所提出的方法有反馈或问题，或者只是想谈论使用 Go 进行开发或关于 Dolt 的问题，请加入我们的 Discord。
]]></content></entry><entry><title>Go实现简单SOCKS5代理服务器</title><url>/posts/go-socks5.html</url><categories><category>go</category></categories><tags><tag>go</tag><tag>socks5</tag></tags><content type="html"><![CDATA[简单实现SOCKS5代理服务器的部分功能：UDP/TCP Proxy， No-Auth Method
一、使用GO的net.listen监听tcp请求 socks5.go
package socks5 import ( &#34;fmt&#34; &#34;log&#34; &#34;net&#34; ) type Server interface { Run() error } type Socks5Server struct { IP string Port int } func (s *Socks5Server) Run() error { addr := fmt.Sprintf(&#34;%s:%d&#34;, s.IP, s.Port) listener, err := net.Listen(&#34;tcp&#34;, addr) if err != nil { return err } for { conn, err := listener.Accept() if err != nil { log.Printf(&#34;Connection failure from %s: %s&#34;, conn.RemoteAddr(), err) continue } go func() { defer conn.Close() err := handleConnection(conn) if err != nil { log.Printf(&#34;handle Connection failure from %s: %s&#34;, conn.RemoteAddr(), err) } }() } } // 处理请求 func handleConnection(conn net.Conn) error { //协商过程 //请求过程 //转发过程 return nil } 二、SOCKS5协商过程 客户端向代理服务器发送代理请求，其中包含了代理的版本和认证方式：
VERNMETHODSMETHODS111 to 255 VER：版本号 - X’04’：Socks4协议 - X’05’：Socks5协议 - NMETHODS：方法数目，该字段包含了METHODS中锁包含了方法识别码的个数 - METHOD ：方法列表 代理服务器从给定的方法列表中选择一个方法并返回选择报文
VERMETHOD11 如果 METHOD （方法）字段为 X’FF‘， 表示方法列表中的所有方法均不可用，客户端收到此信息必须关闭连接。
目前已定义方法如下：
0x00	无需认证 0x01	GSSAPI 0x02	用户名/密码 0x03到0x7F	IANA 指定 0x80到0xFE	为私有方法保留 0xFF	无可接受方法 auth.go
package socks5 import ( &#34;io&#34; ) type Method = byte const ( MethodNoAuth Method = 0x00 MethodGSSAPI Method = 0x01 MethodPASSWORD Method = 0x02 MethodNOACCEPTABLE Method = 0xff ) // 协商消息 type ClientAuthMessage struct { Version byte NMethods byte Methods []Method } // 接收客户端消息 func NewClientAuthMessage(conn io.Reader) (*ClientAuthMessage, error) { //io.ReadFull 从指定的读取器r读取到指定的缓冲区buf //返回指定缓冲区复制的字节数，如果读取的字节数小于指定缓冲区的长度，则返回错误 //当且仅当没有读取字节时，返回的错误是“EOF” //这里读取Version和NMethods buf := make([]byte, 2) _, err := io.ReadFull(conn, buf) if err != nil { return nil, err } //socks5第一位是版本 if buf[0] != Socks5Version { return nil, ErrVersionNotSupported } //第二位是支持多少认证方法 nMethods := buf[1] buf = make([]Method, nMethods) _, err = io.ReadFull(conn, buf) if err != nil { return nil, err } return &amp;ClientAuthMessage{ Version: Socks5Version, NMethods: nMethods, Methods: buf, }, nil } // 服务端返回消息 func NewServerAuthMessage(conn io.Writer, method Method) error { buf := []byte{Socks5Version, method} _, err := conn.Write(buf) return err } type ClientPasswordMessage struct { Username string Password string } const passwordAuthVersion byte = 0x01 const ( passwordAuthSucceeded byte = 0x00 passwordAuthFailure byte = 0x01 ) // 用户名密码认证消息 func NewPasswordAuthMessage(conn io.Reader) (*ClientPasswordMessage, error) { buf := make([]byte, 2) if _, err := io.ReadFull(conn, buf); err != nil { return nil, err } version, ulen := buf[0], buf[1] if version != passwordAuthVersion { return nil, ErrMethodVersionNotSupported } //读取username if int(ulen) &gt; len(buf) { buf = make([]byte, ulen+1) } if _, err := io.ReadFull(conn, buf[:ulen+1]); err != nil { return nil, err } username := string(buf[:ulen]) //读取password plen := buf[ulen] if int(plen) &gt; len(buf) { buf = make([]byte, plen) } if _, err := io.ReadFull(conn, buf[:plen]); err != nil { return nil, err } password := string(buf[:plen]) return &amp;ClientPasswordMessage{username, password}, nil } func NewServerPasswordAuthMessage(conn io.Writer, status byte) error { buf := []byte{passwordAuthVersion, status} _, err := conn.Write(buf) return err } 认证完成后，客户端告诉服务端需要代理访问哪一个远程服务器。
VERCMDRSVATYPDST.ADDRDST.PORT110X001Variable2 VER是版本：0x05
CMD代表客户端请求的类型，值长度是1个字节，有三种类型
CONNECT 0x01 TCP BIND 0x02 建立多个连接通道 UDP ASSOCIATE 0x03 UDP RSV保留字，值长度为1个字节
ATYP代表请求的远程服务器地址类型，值长度1个字节，常用的就三种类型
IP V4 address: 0x01 表示是一个IPV4地址 DOMAINNAME: 0x03 表示是一个域名（DOMAINNAME） IP V6 address: 0x04 表示是一个IPV6地址（IP V6 address） DST.ADDR 代表远程服务器的地址，根据ATYP进行解析，值长度不定。
DST.PORT 代表远程服务器的端口，要访问哪个端口的意思，值长度2个字节。
package socks5 import ( &#34;io&#34; &#34;net&#34; ) type ClientRequestMessage struct { Version byte CMD Command RSV byte AddressType AddressType ADDR string PORT uint16 } type Command byte const ( CommandConnect Command = 0x01 CommandBind Command = 0x02 CommandUDP Command = 0x03 ) type AddressType byte const ( AddressTypeIPV4 AddressType = 0x01 AddressTypeDomain AddressType = 0x03 AddressTypeIPV6 AddressType = 0x04 ) func NewClientRequestMessage(conn io.Reader) (*ClientRequestMessage, error) { //读取前四位 buf := make([]byte, 4) _, err := io.ReadFull(conn, buf) if err != nil { return nil, err } version, command, reserved, addressType := buf[0], Command(buf[1]), buf[2], AddressType(buf[3]) if version != Socks5Version { return nil, ErrVersionNotSupported } if command != CommandConnect &amp;&amp; command != CommandBind &amp;&amp; command != CommandUDP { return nil, ErrCommandNotSupported } if reserved != Socks5Reserved { return nil, ErrReservedNotSupported } if addressType != AddressTypeIPV4 &amp;&amp; addressType != AddressTypeDomain &amp;&amp; addressType != AddressTypeIPV6 { return nil, ErrAddressTypeNotSupported } clientRequestMessage := &amp;ClientRequestMessage{ Version: version, CMD: command, RSV: reserved, AddressType: addressType, } //读取地址 switch addressType { case AddressTypeIPV4: if _, err := io.ReadFull(conn, buf); err != nil { return nil, err } clientRequestMessage.ADDR = net.IP(buf).String() case AddressTypeDomain: if _, err := io.ReadFull(conn, buf[:1]); err != nil { return nil, err } length := buf[0] if length &gt; net.IPv4len { buf = make([]byte, length) } if _, err := io.ReadFull(conn, buf[:length]); err != nil { return nil, err } clientRequestMessage.ADDR = string(buf[:length]) case AddressTypeIPV6: buf = make([]byte, net.IPv6len) if _, err := io.ReadFull(conn, buf); err != nil { return nil, err } clientRequestMessage.ADDR = net.IP(buf).String() } //读取port if _, err := io.ReadFull(conn, buf[:2]); err != nil { return nil, err } clientRequestMessage.PORT = uint16(buf[0])&lt;&lt;8 + uint16(buf[1]) return clientRequestMessage, nil } 接收解析客户端的请求后，请求目标网站，获得与目标网站的连接
func request(conn net.Conn) (io.ReadWriteCloser, error) { message, err := NewClientRequestMessage(conn) if err != nil { return nil, err } if message.CMD == CommandBind { return nil, replyFailureMessage(conn, RepCommandNotSupported) } if message.AddressType == AddressTypeIPV6 { return nil, replyFailureMessage(conn, RepAddressTypeNotSupported) } //请求目标网站 targetConn, err := net.Dial(&#34;tcp&#34;, fmt.Sprintf(&#34;%s:%d&#34;, message.ADDR, message.PORT)) if err != nil { return nil, replyFailureMessage(conn, RepConnectionRefused) } addr := targetConn.LocalAddr().(*net.TCPAddr) return targetConn, replySucceededMessage(conn, byte(message.AddressType), addr.IP, message.PORT) } 最后进行数据转发过程
func forward(conn io.ReadWriter, targetConn io.ReadWriteCloser) error { //io.Copy会阻塞，使用goroutine进行同时接收和发送数据 defer targetConn.Close() go io.Copy(targetConn, conn) _, err := io.Copy(conn, targetConn) return err } ]]></content></entry></search>