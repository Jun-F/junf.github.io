<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>bytebufferpool 源码阅读</title><url>/posts/bytebufferpool/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>byte buffer pool</tag></tags><content type="html"><![CDATA[高性能字节池 bytebufferpool 源码阅读
仓库地址： https://github.com/valyala/bytebufferpool 使用 package main import ( &#34;fmt&#34; &#34;github.com/valyala/bytebufferpool&#34; ) func main() { // 从池中取出一个对象 b := bytebufferpool.Get() b.WriteString(&#34;hello&#34;) b.WriteByte(&#39;,&#39;) b.WriteString(&#34; world!&#34;) fmt.Println(b.String()) // 用完后放回去 bytebufferpool.Put(b) } 源码阅读 源码主要包含两个文件，bytebuffer.go 和 pool.go, bytebuffer.go主要定义了一个ByteBuffer结构体以及一些读取、写入的方法， 池的实现主要是在pool.go。
pool的结构体定义如下：
type Pool struct { calls [steps]uint64 //记录不同长度的索引的使用次数 calibrating uint64 //防止校准并发的标志位 defaultSize uint64 //初始化[]byte的默认值 maxSize uint64 //可放回pool中的最大[]byte长度 pool sync.Pool } 首先看Get方法，从sync.Pool中取出一个对象，如果没有就初始化一个ByteBuffer，然后返回。
func (p *Pool) Get() *ByteBuffer { v := p.pool.Get() if v != nil { return v.(*ByteBuffer) } return &amp;ByteBuffer{ B: make([]byte, 0, atomic.LoadUint64(&amp;p.defaultSize)), } } 当对象使用完，放回池中时，使用index方法根据[]byte的长度计算出索引。
// minBitSize=6 steps=20 // 将[]byte的长度映射为0-19的索引 func index(n int) int { n-- n &gt;&gt;= minBitSize idx := 0 for n &gt; 0 { n &gt;&gt;= 1 idx++ } if idx &gt;= steps { idx = steps - 1 } return idx } 然后给相应位置的索引+1，如果大于42000这个阈值，就触发校准
if atomic.AddUint64(&amp;p.calls[idx], 1) &gt; calibrateCallsThreshold { p.calibrate() } 如果要回收的对象的容量小于maxSize 或者 maxSize为0(默认值),就执行reset后放回池中，容量超过maxSize就丢弃。
maxSize := int(atomic.LoadUint64(&amp;p.maxSize)) if maxSize == 0 || cap(b.B) &lt;= maxSize { b.Reset() p.pool.Put(b) } 关键在于calibrate方法，在区间的使用次数超过阈值之后，就会触发校准，调整defaultSize和maxSize的值。
首先使用原子操作修改calibrating，防止并发。
if !atomic.CompareAndSwapUint64(&amp;p.calibrating, 0, 1) { return } 然后遍历calls数组，得出所有区间调用次数和容量，再进行排序。然后defaultSize设置为第一个的容量，即使用次数最多的。
a := make(callSizes, 0, steps) var callsSum uint64 for i := uint64(0); i &lt; steps; i++ { calls := atomic.SwapUint64(&amp;p.calls[i], 0) callsSum += calls a = append(a, callSize{ calls: calls, size: minSize &lt;&lt; i, }) } sort.Sort(a) defaultSize := a[0].size 然后遍历计算maxSize，取调用次数为总次数前95%的buffer的最大容量。 比如：callsSum=1000，即调用了1000次，那么maxSum=950，然后遍历加上调用次数，如果总数小于950， 且size &gt; maxSize, 就把当前size的值赋值给maxSize，最后得出最大的maxSize。
maxSize := defaultSize //maxPercentile=0.95 maxSum := uint64(float64(callsSum) * maxPercentile) callsSum = 0 for i := 0; i &lt; steps; i++ { if callsSum &gt; maxSum { break } callsSum += a[i].calls size := a[i].size if size &gt; maxSize { maxSize = size } } 最后使用原子操作修改defaultSize和maxSize
atomic.StoreUint64(&amp;p.defaultSize, defaultSize) atomic.StoreUint64(&amp;p.maxSize, maxSize) 总结 相比sync.Pool, 这个库可用根据实际使用的数据的大小，实时调整[]byte对象的大小， 抛弃调用次数比较少的对象，防止将使用较少的大容量对象放回对象池 ，从而占用太多内存。
]]></content></entry><entry><title>在Go中初始化大型static Maps</title><url>/posts/static-map-initialization-in-go/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[文章翻译，原文链接：https://www.dolthub.com/blog/2023-06-16-static-map-initialization-in-go/
这篇文章讨论了Go二进制文件中map数据的静态初始化的技术细节，以及处理性能影响的一些替代策略。这是我们技术博客系列中的一部分。我们每三周发布一篇新的系列文章。
在Dolt中，我们正在构建一个带有类似Git版本控制功能的SQL数据库。 它支持克隆、推送、拉取、分支、合并和差异等所有核心Git习语。 它使用Go语言实现，其协议和SQL方言与MySQL兼容。
在过去的几个月中，我们一直在改进我们的SQL引擎中的排序规则和Unicode支持。 我们所做的一个改变是向Dolt中添加了一些数据表，以更好地支持不同Unicode区域设置下字符串的本地化排序。 这涉及向Dolt二进制文件中添加了许多静态数据表。 我们最初的实现是使用static Maps，将这些maps编译到Dolt二进制文件中。 不久之后，一位同事在一个Pull Request中添加了许多大型static Maps到Dolt后，我们发现端到端测试变得非常缓慢。 这促使我们深入研究Go中static Map初始化的工作原理，并在后续版本中解决这个回归问题：
这篇博客是对Go工具链中static Maps初始化的实现方式进行简要探索，以及它在运行时的开销成本以及一些备选方法，用于在需要时处理相关问题。
背景 Dolt与MySQL一样，并且作为其MySQL兼容性的一部分，支持字符串的语言相关排序。 语言相关排序涉及将字符串相互比较，并得出语言用户所期望的相对顺序。 对于大多数字符编码和区域设置而言，这比简单比较字符串中字符或代码点的二进制表示更为复杂。原因包括：
相同字符串的不同表示在给定字符编码中可以有不同的二进制表示形式，根据用户在屏幕上的显示方式。例如，在UTF-32中，法语单词&quot;où&quot;可以用两个代码单元表示为：[U+006F, U+00F9]，或者用三个代码单元表示，带有表示重音的组合附加符号：[U+006F, U+0300, U+0075]。 不同语言对于相同字符的相对顺序有不同的规则。例如，在德语区域设置下，字符串列表[&ldquo;Aa&rdquo;, &ldquo;Od&rdquo;, &ldquo;Öd&rdquo;, &ldquo;Zz&rdquo;]应按相同顺序排序，但在瑞典语区域设置下应排序为[&ldquo;Aa&rdquo;, &ldquo;Od&rdquo;, &ldquo;Zz&rdquo;, &ldquo;Öd&rdquo;]。 你可以在Dolt中看到这一点的实际应用：
collations&gt; create table german (word varchar(32) primary key) collate utf8mb4_de_pb_0900_as_cs; collations&gt; create table swedish (word varchar(32) primary key) collate utf8mb4_sv_0900_as_cs; collations&gt; insert into german values (&#34;Aa&#34;),(&#34;Od&#34;),(&#34;Öd&#34;),(&#34;Zz&#34;); Query OK, 4 rows affected (0.02 sec) collations&gt; insert into swedish values (&#34;Aa&#34;),(&#34;Od&#34;),(&#34;Öd&#34;),(&#34;Zz&#34;); Query OK, 4 rows affected (0.01 sec) collations&gt; select * from german order by word asc; +------+ | word | +------+ | Aa | | Od | | Öd | | Zz | +------+ 4 rows in set (0.01 sec) collations&gt; select * from swedish order by word asc; +------+ | word | +------+ | Aa | | Od | | Zz | | Öd | +------+ 4 rows in set (0.00 sec) 由于存在这样的复杂性，实现与地区相关的排序通常涉及到调用排序算法相关的数据表，以获得字符串的适当顺序。
Dolt本身作为静态链接的二进制文件分发。我们非常喜欢它的分发模型的可接近性和易用性。 您只需下载Dolt的操作系统适当版本并运行即可。 因此，我们始终在二进制文件中提供这些表，以支持Dolt的排序。
Dolt的用户体验和典型交互方式与典型的SQL服务器也可能非常不同。 具体而言，Dolt用户通常以两种不同的方式与Dolt交互：
作为SQL服务器，长时间运行的Dolt进程通过TCP 和/或 Unix套接字接受SQL连接。 作为独立的二进制文件，在类似Git的工作流中频繁调用Dolt CLI来执行诸如创建分支、运行临时SQL查询、查看提交日志和执行合并等操作。 后一种情况与传统RDBMS实现的典型交互方式非常不同，这意味着使用Dolt的用户体验可能在很大程度上受到Dolt二进制启动延迟的影响。
我的同事最近向Dolt二进制文件添加了32MB以上的排序数据表，以更好地支持MySQL支持的许多Unicode排序。 这些最初是以与现有排序实现完全相同的方式完成的。 数据负载的大部分是作为静态初始化的Go map实现的，类似于：
var utf16_spanish_ci_Weights = map[rune]int32{ 9: 0, 10: 1, 11: 2, 12: 3, 13: 4, 133: 5, 8232: 6, // ... // ... // ... 24000+ lines later ... 65534: 59403, 65535: 59404, } PR合并后不久，我们注意到我们的端到端测试变得非常慢。 当我们进行基准测试时，发现由于static Maps，dolt &ndash;help的速度变慢了300%以上。 在意识到static Maps的运行时初始化成本后，我们将它们移动到embed数据文件中，在需要时再加载，修复了整个回归。
让我们来看看Go static Maps初始化的工作原理以及我们对其运行时开销的预期。
Static Map 初始化 static Maps的初始化发生在创建一个具有初始内容的Map时，该Map位于Go包的顶层。 与某些其他静态数据类型（包括原始类型、字符串、切片和所有这些类型的结构体）不同， 在Go中，static Maps是在程序初始化时动态分配和赋值的，而不是将其内容放到内存中并写入编译二进制文件的数据段中。例如：
package main var mymap = map[int]int{ 1: 1, 2: 2, 3: 3, } Go编译器将调用一个init函数，其中包括分配map并将元素插入其中。 代码看起来几乎与以下Go代码序列完全相同：
mymap = make(map[int]int, 3) mymap[1] = 1 mymap[2] = 2 mymap[3] = 3 调用了runtime.makemap_small和三次调用runtime.mapassign_fast64。
在当前版本的golang编译器中，随着map的大小变化，这种方法会略微改变。 受到代码大小的限制，如果map中有超过25个条目，编译器将移动键和值数据到静态数组中。 在这种情况下，init代码会循环遍历静态数组数据并将其插入动态分配的map中。
总体效果是，static Maps初始化的成本随着Go二进制文件中static Maps大小的增加大约呈线性增长。 在一些本地运行的实验中，我看到以下的缩放行为： 我们可以看到，一旦map初始化的成本高到足以开始产生影响，其成本就会近似于线性增长。
对开发工作流程的影响 除了生成的二进制文件的启动成本外，以static Maps初始化的形式存在的巨大代码也对编译时间和诸如go vet之类的操作的内存开销产生了负面影响。 这一点并不令人惊讶，因为需要编译的代码量要大得多。 在一个测试程序中，该程序包含一个具有2^20个整数条目的map，总共占据17MB的磁盘空间， go vet的最大常驻堆利用率超过了1.5GB，go build的常驻堆利用率超过了1.2GB， 构建该软件包需要超过12秒的时间。
一些解决方法 考虑到相关成本，我们可以采取许多不同的方法，以在启动开销、代码易用性和可访问性以及生成的初始化数据结构中可用的各种功能方面进行不同的权衡。 在这里，我们将讨论三个令人信服的替代方案，这些方案在转换后的复杂性和可用功能方面有所不同。根据您的用例，这些替代方案中的任何一个或所有方案都可能是合适的。
排序的静态数组 如果你能负担得起在二进制文件中嵌入的任何表的查找路径上的O(lg n)比较， 而且你主要关心的是启动开销，而不一定是与大的代码有效载荷相关的资源开销， 那么把maps转换成一个排序的静态数组可能是一个选择。使用这种方法，你会失去：
数据结构在运行时易于更改。 O(1) 时间复杂度 采用这种方法，您可能会牺牲嵌入式数组文字的易于手动编辑性。 如果采用这种方法，文字实际上需要进行排序，因此您应编写单元测试来进行断言。 作为额外的好处，这些同样的单元测试还可以在失败时生成嵌入排序结果的代码，以便开发人员可以轻松地将正确结果复制到代码中。
采用这种方法，上面的示例map可能如下所示：
type RuneCollationWeight struct { R rune W int } type RuneCollationWeights []RuneCollationWeight func (w RuneCollationWeights) Len() int { return len(w) } func (w RuneCollationWeights) Less(i, j int) bool { return w[i].R &lt; w[j].R } func (w RuneCollationWeights) Swap(i, j int) { w[i], w[j] = w[j], w[i] } func (w RuneCollationWeights) Get(r rune) (int, bool) { n := sort.Search(w.Len(), func(i int) bool { return w[i].R &gt;= r }) entry := w[n] if entry.R == r { return entry.W, true } else { return 0, false } } var utf16_spanish_ci_Weights = RuneCollationWeights{ {9, 0}, {10, 1}, {11, 2}, {12, 3}, {13, 4}, {133, 5}, {8232, 6}, // ... // ... // ... 24000+ lines later ... {65534, 59403}, {65535, 59404}, } 这里的代码实现了sort.Interface，因此可以进行一些健全性测试，例如sort.IsSorted(utf16_spanish_ci_Weights)。
使用embed减少代码量 根据实际情况，在 Go 代码中保留数组可能会对开发人员的工作效率产生不良影响， 例如编译和 go vet 时间的开销。 Go 通过其 embed 包提供了一种非常简单的方法，可以将二进制有效负载嵌入为 []bytes，甚至可以将整个目录树作为 fs.FS 实现嵌入。
使用这种方法，可以将大型静态数组从 Go 代码本身移出，并放入外部文件中。 在这样做时，需要考虑将数据本身序列化到外部文件中。该序列化需要以跨平台的方式进行处理。 还需要添加能够在更改文件时生成这些文件的程序或构建过程。 对于上面的示例，可以编写一个简单的程序，将数据序列化为大端 int32：
func SerializeWeights(w io.Writer, weights RuneCollationWeights) error { sort.Sort(weights) for _, weight := range weights { if weight.W &gt; math.MaxInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is larger than MaxInt32&#34;, weight.R, weight.W) } if weight.W &lt; math.MinInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is smaller than MinInt32&#34;, weight.R, weight.W) } err = binary.Write(w, binary.BigEndian, int32(weight.R)) if err != nil { return err } err = binary.Write(w, binary.BigEndian, int32(weight.W)) if err != nil { return err } } return nil } 正如您所看到的，我们可以选择将权重排序作为构建步骤的一部分，这可能会使与这些生成器程序源代码一起检入的数组的处理更加容易。 要将这些文件发布并在二进制文件中使用它们，我们可以采用上述方法，但这次利用使用 embed 包生成的文件：
import _ &#34;embed&#34; //go:embed utf16_spanish_ci_Weights.bin var utf16_spanish_ci_Weights_bin []byte type BinaryRuneCollationWeights []byte func (w BinaryRuneCollationWeights) Len() int { // There are two 32-bit integers per entry return len(w) / 8 } func (w BinaryRuneCollationWeights) Get(r rune) (int, bool) { n := sort.Search(w.Len(), func(i int) bool { entryR := binary.BigEndian.Uint32(w[i*8:]) return rune(entryR) &gt;= r }) entryR := binary.BigEndian.Uint32(w[n*8:]) if rune(entryR) == r { return int(int32(binary.BigEndian.Uint32(w[n*8+4:]))), true } else { return 0, false } } var utf16_spanish_ci_Weights = BinaryRuneCollationWeights(utf16_spanish_ci_Weights_bin) 懒加载Maps 如果您想要 O(1) 时间复杂度，并且特别是如果您希望在用初始内容填充map后保持map运行时的可变性， 则在首次访问时懒加载map可能是一个不错的选择。 如果您的程序不是所有运行都需要访问map（或在您有多个map的情况下不是所有map都需要访问），那么这尤其正确。 实现这个的最简单方法是将map访问移至函数调用后面，并在该函数内使用 sync.Once 调用来填充map内容。类似于这样的东西：
import &#34;sync&#34; var utf16_spanish_ci_Weights_ map[rune]int var utf16_spanish_ci_Weights_once sync.Once func utf16_spanish_ci_Weights() map[rune]int { utf16_spanish_ci_Weights_once.Do(func() { utf16_spanish_ci_Weights_ = map[rune]int{ 9: 0, 10: 1, 11: 2, 12: 3, 13: 4, 133: 5, 8232: 6, // ... // ... // ... 24000+ lines later ... 65534: 59403, 65535: 59404, } }) return utf16_spanish_ci_Weights_ } 每次访问您的map都应该通过 utf16_spanish_ci_Weights() 进行访问。 如果您只关心启动初始化开销，那么这种转换就足够了。 utf16_spanish_ci_Weights() 函数内部的代码几乎与 init 函数中编译的代码相同， 但所有这些工作都被延迟到实际访问权重map时才执行。
如果您想要将代码负载本身从常见的编译、测试或依赖代码路径中取出， 则可以像上面那样使用 embed，并从 sync.Once 回调中的序列化内容中构建map。类似于这样的东西：
func utf16_spanish_ci_Weights() map[rune]int { utf16_spanish_ci_Weights_once.Do(func() { bin := utf16_spanish_ci_Weights_bin utf16_spanish_ci_Weights_ = make(map[rune]int, len(bin) / 8) for len(bin) &gt; 0 { r := rune(binary.BigEndian.Uint32(bin[:])) w := int(int32(binary.BigEndian.Uint32(bin[4:]))) utf16_spanish_ci_Weights_[r] = w bin = bin[8:] } }) return utf16_spanish_ci_Weights_ } 这是我们在 dolt 中实现的解决方案，因为它很简单，并且对使用这些数据表内容的代码影响最小。
完美哈希 由于依赖于 embed 的解决方案需要外部程序处理数据表并将其放入程序可以使用的格式中（而不是仅仅依靠 Go 编译器的能力来布局程序的静态数据）， 因此我们可以进一步采用一种紧凑、哈希方式来布局数据，这仍然允许 O(1) 访问所有条目， 但不需要在运行时构建map。我们想要的结构是一个查找表，建立在我们原始map中的键的计算最小完美哈希函数上。在Golang中有许多高质量的最小完美哈希实现。
我们为map的keys构建和序列化完美哈希函数，作为与map内容本身分开的有效负载。 该有效负载通常比键和值本身的集合小得多。 我们将键和值嵌入为单独的二进制有效负载，通过完美哈希间接引用。以下是使用 bbhash 包的运行示例：
func SerializeWeights(wWr, hWr io.Writer, weights []RuneCollationWeight) error { keys := make([]uint64, len(weights)) for i, weight := range weights { keys[i] = uint64(weight.R) } hash, err := bbhash.New(bbhash.Gamma, keys) if err != nil { return err } err = hash.MarshalBinary(hWr) if err != nil { return err } ordered := make([]RuneCollationWeight, len(weights)) for _, weight := range weights { i := hash.Find(uint64(weight.R)) - 1 ordered[i] = weight } for _, weight := range ordered { if weight.W &gt; math.MaxInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is larger than MaxInt32&#34;, weight.R, weight.W) } if weight.W &lt; math.MinInt32 { return fmt.Errorf(&#34;cannot serialize weights: weight for %d, %d, is smaller than MinInt32&#34;, weight.R, weight.W) } err = binary.Write(wWr, binary.BigEndian, int32(weight.R)) if err != nil { return err } err = binary.Write(wWr, binary.BigEndian, int32(weight.W)) if err != nil { return err } } return nil } import _ &#34;embed&#34; //go:embed utf16_spanish_ci_Weights.bin var utf16_spanish_ci_Weights_bin []byte //go:embed utf16_spanish_ci_Weights_hash.bin var utf16_spanish_ci_Weights_hash_bin []byte var utf16_spanish_ci_Weights_hash *bbhash.BBHash var utf16_spanish_ci_Weights HashedRuneCollationWeights func init() { var err error utf16_spanish_ci_Weights_hash, err = bbhash.UnmarshalBBHash(bytes.NewReader(utf16_spanish_ci_Weights_hash_bin)) if err != nil { panic(err) } utf16_spanish_ci_Weights = HashedRuneCollationWeights{ H: utf16_spanish_ci_Weights_hash, B: utf16_spanish_ci_Weights_bin, } } type HashedRuneCollationWeights struct { H *bbhash.BBHash B []byte } func (w HashedRuneCollationWeights) Get(r rune) (int, bool) { i := h.Find(uint64(r)) - 1 off := i * 8 if off &lt; len(w.B) { entryR := rune(binary.BigEndian.Uint32(w.B[off:])) entryW := int(int32(binary.BigEndian.Uint32(w.B[off+4:]))) if entryR == r { return entryW, true } } return 0, false } 如果您试图削减初始化开销，那么这可能是您想要采取的方法， 但实际上有很大一部分二进制调用实际上确实需要访问这些嵌入式数据表的至少一些部分。 在这种情况下，无法避免支付初始化开销，因此最好尽可能少。
这种方法的一些缺点可能包括：
重新生成序列化数据表需要更多时间，因为它需要在生成时计算键集的最小完美哈希。 如果数据表被检入源代码控制，它们将按哈希顺序存储，而不是按排序顺序存储。这通常会导致更少的二进制差异和更高的存储开销，因为版本之间的更改会更大，而SCM使用的增量编码也不太有效。 生成的二进制文件略大，因为它存储足够的数据来重构哈希表map以及数据表的实际内容。 值得注意的是，上面 init 函数中的 bbhash.UnmarshalBBHash 调用的静态初始化开销介于类似于 []byte 的纯静态数据和初始化map之间。 它需要解析一些位向量，这些位向量在聚合大小为 O(n)，通常每个键不到五个位，并且它通过并解释大多数加载的数据作为小端整数。 这可以非常快地完成，比构建哈希map快得多，但它不像根本不访问内存那样便宜——如果大型静态数组写入 Golang 二进制文件的数据段中，如果它们未被访问，则在启动时甚至不需要从磁盘中分页。
如果您通常喜欢完美哈希的某些属性，但不喜欢特定的初始化开销，将 UnmarshalBBHash 移动为延迟加载也可以正常工作。
总结 概括一下，我们研究了以下在Dolt二进制文件中嵌入大型静态查找表的方法：
Approach Startup Cost First Access Cost Code Cost Build Complexity Access Asymptotics Runtime Mutability Static Map ★☆☆☆☆ ★★★★★ ★☆☆☆☆ ★★★★★ O(1) ✔️ Lazy Map ★★★★★ ★☆☆☆☆ ★☆☆☆☆ ★★★★★ O(1) ✔️ Lazy Map, using embed ★★★★★ ★☆☆☆☆ ★★★★★ ★★☆☆☆ O(1) ✔️ Static Array ★★★★★ ★★★★★ ★☆☆☆☆ ★★★★★ O(lg n)	❌ Static Array, using embed ★★★★★ ★★★★★ ★★★★★ ★★☆☆☆ O(lg n) ❌ Perfect Hash ★★★★☆ ★★★★★ ★★★★★ ★☆☆☆☆ O(1) ❌ 在 Dolt 本身中，我们最终使用了延迟初始化的map，我们从 embed 数据表中在第一次访问时构建。 外部程序将序列化的数据表写出，然后我们将二进制有效负载检入源代码控制。 对于我们来说，这很有效，因为这些表缓慢地变化，每个表的中等大小有很多，对于我们大多数客户的大多数 Dolt 调用，只访问其中很少的几个。
正如您所看到的，Go 工具链和生态系统提供了许多近在手边的方法，希望能够满足您在二进制文件中发布大型查找表的分发和开发人员工程学需求。 如果您对所提出的方法有反馈或问题，或者只是想谈论使用 Go 进行开发或关于 Dolt 的问题，请加入我们的 Discord。
]]></content></entry><entry><title>Go实现简单SOCKS5代理服务器</title><url>/posts/go-socks5.html</url><categories><category>go</category></categories><tags><tag>go</tag><tag>socks5</tag></tags><content type="html"><![CDATA[简单实现SOCKS5代理服务器的部分功能：UDP/TCP Proxy， No-Auth Method
一、使用GO的net.listen监听tcp请求 socks5.go
package socks5 import ( &#34;fmt&#34; &#34;log&#34; &#34;net&#34; ) type Server interface { Run() error } type Socks5Server struct { IP string Port int } func (s *Socks5Server) Run() error { addr := fmt.Sprintf(&#34;%s:%d&#34;, s.IP, s.Port) listener, err := net.Listen(&#34;tcp&#34;, addr) if err != nil { return err } for { conn, err := listener.Accept() if err != nil { log.Printf(&#34;Connection failure from %s: %s&#34;, conn.RemoteAddr(), err) continue } go func() { defer conn.Close() err := handleConnection(conn) if err != nil { log.Printf(&#34;handle Connection failure from %s: %s&#34;, conn.RemoteAddr(), err) } }() } } // 处理请求 func handleConnection(conn net.Conn) error { //协商过程 //请求过程 //转发过程 return nil } 二、SOCKS5协商过程 客户端向代理服务器发送代理请求，其中包含了代理的版本和认证方式：
VERNMETHODSMETHODS111 to 255 VER：版本号 - X’04’：Socks4协议 - X’05’：Socks5协议 - NMETHODS：方法数目，该字段包含了METHODS中锁包含了方法识别码的个数 - METHOD ：方法列表 代理服务器从给定的方法列表中选择一个方法并返回选择报文
VERMETHOD11 如果 METHOD （方法）字段为 X’FF‘， 表示方法列表中的所有方法均不可用，客户端收到此信息必须关闭连接。
目前已定义方法如下：
0x00	无需认证 0x01	GSSAPI 0x02	用户名/密码 0x03到0x7F	IANA 指定 0x80到0xFE	为私有方法保留 0xFF	无可接受方法 auth.go
package socks5 import ( &#34;io&#34; ) type Method = byte const ( MethodNoAuth Method = 0x00 MethodGSSAPI Method = 0x01 MethodPASSWORD Method = 0x02 MethodNOACCEPTABLE Method = 0xff ) // 协商消息 type ClientAuthMessage struct { Version byte NMethods byte Methods []Method } // 接收客户端消息 func NewClientAuthMessage(conn io.Reader) (*ClientAuthMessage, error) { //io.ReadFull 从指定的读取器r读取到指定的缓冲区buf //返回指定缓冲区复制的字节数，如果读取的字节数小于指定缓冲区的长度，则返回错误 //当且仅当没有读取字节时，返回的错误是“EOF” //这里读取Version和NMethods buf := make([]byte, 2) _, err := io.ReadFull(conn, buf) if err != nil { return nil, err } //socks5第一位是版本 if buf[0] != Socks5Version { return nil, ErrVersionNotSupported } //第二位是支持多少认证方法 nMethods := buf[1] buf = make([]Method, nMethods) _, err = io.ReadFull(conn, buf) if err != nil { return nil, err } return &amp;ClientAuthMessage{ Version: Socks5Version, NMethods: nMethods, Methods: buf, }, nil } // 服务端返回消息 func NewServerAuthMessage(conn io.Writer, method Method) error { buf := []byte{Socks5Version, method} _, err := conn.Write(buf) return err } type ClientPasswordMessage struct { Username string Password string } const passwordAuthVersion byte = 0x01 const ( passwordAuthSucceeded byte = 0x00 passwordAuthFailure byte = 0x01 ) // 用户名密码认证消息 func NewPasswordAuthMessage(conn io.Reader) (*ClientPasswordMessage, error) { buf := make([]byte, 2) if _, err := io.ReadFull(conn, buf); err != nil { return nil, err } version, ulen := buf[0], buf[1] if version != passwordAuthVersion { return nil, ErrMethodVersionNotSupported } //读取username if int(ulen) &gt; len(buf) { buf = make([]byte, ulen+1) } if _, err := io.ReadFull(conn, buf[:ulen+1]); err != nil { return nil, err } username := string(buf[:ulen]) //读取password plen := buf[ulen] if int(plen) &gt; len(buf) { buf = make([]byte, plen) } if _, err := io.ReadFull(conn, buf[:plen]); err != nil { return nil, err } password := string(buf[:plen]) return &amp;ClientPasswordMessage{username, password}, nil } func NewServerPasswordAuthMessage(conn io.Writer, status byte) error { buf := []byte{passwordAuthVersion, status} _, err := conn.Write(buf) return err } 认证完成后，客户端告诉服务端需要代理访问哪一个远程服务器。
VERCMDRSVATYPDST.ADDRDST.PORT110X001Variable2 VER是版本：0x05
CMD代表客户端请求的类型，值长度是1个字节，有三种类型
CONNECT 0x01 TCP BIND 0x02 建立多个连接通道 UDP ASSOCIATE 0x03 UDP RSV保留字，值长度为1个字节
ATYP代表请求的远程服务器地址类型，值长度1个字节，常用的就三种类型
IP V4 address: 0x01 表示是一个IPV4地址 DOMAINNAME: 0x03 表示是一个域名（DOMAINNAME） IP V6 address: 0x04 表示是一个IPV6地址（IP V6 address） DST.ADDR 代表远程服务器的地址，根据ATYP进行解析，值长度不定。
DST.PORT 代表远程服务器的端口，要访问哪个端口的意思，值长度2个字节。
package socks5 import ( &#34;io&#34; &#34;net&#34; ) type ClientRequestMessage struct { Version byte CMD Command RSV byte AddressType AddressType ADDR string PORT uint16 } type Command byte const ( CommandConnect Command = 0x01 CommandBind Command = 0x02 CommandUDP Command = 0x03 ) type AddressType byte const ( AddressTypeIPV4 AddressType = 0x01 AddressTypeDomain AddressType = 0x03 AddressTypeIPV6 AddressType = 0x04 ) func NewClientRequestMessage(conn io.Reader) (*ClientRequestMessage, error) { //读取前四位 buf := make([]byte, 4) _, err := io.ReadFull(conn, buf) if err != nil { return nil, err } version, command, reserved, addressType := buf[0], Command(buf[1]), buf[2], AddressType(buf[3]) if version != Socks5Version { return nil, ErrVersionNotSupported } if command != CommandConnect &amp;&amp; command != CommandBind &amp;&amp; command != CommandUDP { return nil, ErrCommandNotSupported } if reserved != Socks5Reserved { return nil, ErrReservedNotSupported } if addressType != AddressTypeIPV4 &amp;&amp; addressType != AddressTypeDomain &amp;&amp; addressType != AddressTypeIPV6 { return nil, ErrAddressTypeNotSupported } clientRequestMessage := &amp;ClientRequestMessage{ Version: version, CMD: command, RSV: reserved, AddressType: addressType, } //读取地址 switch addressType { case AddressTypeIPV4: if _, err := io.ReadFull(conn, buf); err != nil { return nil, err } clientRequestMessage.ADDR = net.IP(buf).String() case AddressTypeDomain: if _, err := io.ReadFull(conn, buf[:1]); err != nil { return nil, err } length := buf[0] if length &gt; net.IPv4len { buf = make([]byte, length) } if _, err := io.ReadFull(conn, buf[:length]); err != nil { return nil, err } clientRequestMessage.ADDR = string(buf[:length]) case AddressTypeIPV6: buf = make([]byte, net.IPv6len) if _, err := io.ReadFull(conn, buf); err != nil { return nil, err } clientRequestMessage.ADDR = net.IP(buf).String() } //读取port if _, err := io.ReadFull(conn, buf[:2]); err != nil { return nil, err } clientRequestMessage.PORT = uint16(buf[0])&lt;&lt;8 + uint16(buf[1]) return clientRequestMessage, nil } 接收解析客户端的请求后，请求目标网站，获得与目标网站的连接
func request(conn net.Conn) (io.ReadWriteCloser, error) { message, err := NewClientRequestMessage(conn) if err != nil { return nil, err } if message.CMD == CommandBind { return nil, replyFailureMessage(conn, RepCommandNotSupported) } if message.AddressType == AddressTypeIPV6 { return nil, replyFailureMessage(conn, RepAddressTypeNotSupported) } //请求目标网站 targetConn, err := net.Dial(&#34;tcp&#34;, fmt.Sprintf(&#34;%s:%d&#34;, message.ADDR, message.PORT)) if err != nil { return nil, replyFailureMessage(conn, RepConnectionRefused) } addr := targetConn.LocalAddr().(*net.TCPAddr) return targetConn, replySucceededMessage(conn, byte(message.AddressType), addr.IP, message.PORT) } 最后进行数据转发过程
func forward(conn io.ReadWriter, targetConn io.ReadWriteCloser) error { //io.Copy会阻塞，使用goroutine进行同时接收和发送数据 defer targetConn.Close() go io.Copy(targetConn, conn) _, err := io.Copy(conn, targetConn) return err } ]]></content></entry></search>